{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875e45fd-99b7-47a3-8985-338a47936a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the module: helpers.mpl_plotting_helpers\n",
      "\n",
      "Loading the module: helpers.general_helpers\n",
      "\n",
      "Loading the module: helpers.argcheck_helpers\n",
      "\n",
      "Loading the module: helpers.pandas_helpers\n",
      "\n",
      "Loading the module: helpers.stats_helpers.py\n",
      "\n",
      "numpy        2.2.5\n",
      "scipy         1.15.2\n",
      "pandas        2.2.3\n",
      "\n",
      "pandas        2.2.3\n",
      "numpy         2.2.5\n",
      "\n",
      "matplotlib    3.10.1\n",
      "numpy         2.2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "#\n",
    "# Imporatbles, just the basics :P\n",
    "\n",
    "    # My module, cuz I'm cool\n",
    "from helpers import mpl_plotting_helpers as mph\n",
    "from helpers import stats_helpers as sh\n",
    "from helpers import general_helpers as gh\n",
    "from helpers import western_helpers as wh\n",
    "from helpers.mph_modules.dotplots import get_data_info, add_errorbar\n",
    "#from functions import *\n",
    "\n",
    "    # Standard packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as mpl_fm\n",
    "from math import floor, ceil, log2\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#\n",
    "#\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d48ad90-33f3-4a85-8a24-95c67526725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logical_ignore_comps(labelled_line_groups,\n",
    "                          group_strs,\n",
    "                          xgroup_strs):\n",
    "    \"\"\"\n",
    "    Only want to compare along a line group (e.g. timecourse) or\n",
    "    down an x-column (e.g. JE6 DMSO 0m vs JE6 U0126 0m), but not\n",
    "    all the random other comparisons because statistically they're\n",
    "    kind of useless\n",
    "    \n",
    "    So this function will find all of the pairs that are useless\n",
    "    \"\"\"\n",
    "    groups_unpacked = []\n",
    "    for group in labelled_line_groups:\n",
    "        groups_unpacked += group\n",
    "    # This will hold the ignored pairs\n",
    "    ignore_me_senpai = []\n",
    "    # First, get all pairs\n",
    "    paired = gh.make_pairs(groups_unpacked,\n",
    "                           dupes = False,\n",
    "                           reverse = False)\n",
    "    # Then iterate over and check the labels\n",
    "    for p in paired:\n",
    "        gs_check = 0\n",
    "        xs_check = 0\n",
    "        # Check all the group strings\n",
    "        for gs in group_strs:\n",
    "            if gs_check == 1:\n",
    "                pass\n",
    "            elif gs in p[0][0] and gs in p[1][0]:\n",
    "                gs_check = 1\n",
    "        # Check all the xgroup strings\n",
    "        for xs in xgroup_strs:\n",
    "            if xs_check == 1:\n",
    "                pass\n",
    "            elif xs in p[0][0] and xs in p[1][0]:\n",
    "                xs_check = 1\n",
    "        # If there isn't a match, in either, ignore\n",
    "        if gs_check == 0 and xs_check == 0:\n",
    "            ignore_me_senpai.append(p)\n",
    "    # Return the ignored pairs at the end\n",
    "    return ignore_me_senpai\n",
    "\n",
    "def perform_line_statistics(labelled_line_groups,\n",
    "                            ignore_comps,\n",
    "                            comp_type,\n",
    "                            statsfile):\n",
    "    \"\"\"\n",
    "    labelled_line_groups -> data with labels\n",
    "                            list of lists of [label, [d1,d2,...,dn]]\n",
    "    ignore_comps -> list of pairs (\"group 1\", \"group 2\") to not be\n",
    "                    compared\n",
    "    comp_type -> statistics to use, currently only\n",
    "                 [\"HolmSidak\", \"TukeyHSD\"] are supported\n",
    "                 (both do an ANOVA first by default)\n",
    "    statsfile -> a string to the output path and filename\n",
    "                 for the statistics file output\n",
    "    #####\n",
    "    Returns None, just dumps the statsfile\n",
    "    \"\"\"\n",
    "    assert comp_type in [\"HolmSidak\", \"TukeyHSD\"], f\"Invalid comparison type: {comp_type}\"\n",
    "    groups_unpacked = []\n",
    "    for group in labelled_line_groups:\n",
    "        groups_unpacked += group\n",
    "    if comp_type == \"HolmSidak\":\n",
    "        comparison = sh.HolmSidak(*groups_unpacked,\n",
    "                                  labels = True,\n",
    "                                  override = True,\n",
    "                                  alpha = 0.05,\n",
    "                                  no_comp = ignore_comps)\n",
    "    elif comp_type == \"TukeyHSD\":\n",
    "        comparison = sh.TukeyHSD(*groups_unpacked,\n",
    "                                  labels = True,\n",
    "                                  override = True,\n",
    "                                  alpha = 0.05,\n",
    "                                  no_comp = ignore_comps)\n",
    "    comparison.write_output(filename = statsfile,\n",
    "                            file_type = \"csv\")\n",
    "    return None\n",
    "\n",
    "def find_centres(plotting_info):\n",
    "    \"\"\"\n",
    "    plotting_info -> output from get_data_info, a list of\n",
    "                     data info and the raw data\n",
    "                     \n",
    "    goal: grab the centres for xticks\n",
    "    \"\"\"\n",
    "    centres = []\n",
    "    for group in plotting_info:\n",
    "        if len(centres) <= len(group[0][\"centers\"]):\n",
    "            centres = group[0][\"centers\"]\n",
    "    return centres\n",
    "\n",
    "def line_plot(labelled_line_groups,\n",
    "              show_points = False,\n",
    "              show_legend = False,\n",
    "              colours = [\"grey\" for _ in range(20)],\n",
    "              group_labs = [f\"Thing {i}\" for i in range(20)],\n",
    "              markers = [\"s\" for _ in range(20)],\n",
    "              linestyles = [\"solid\" for _ in range(20)],\n",
    "              xlabels = [f\"Time {i}\" for i in range(20)],\n",
    "              ylabel = [\"Fold change\"],\n",
    "              ylims = None,\n",
    "              ignore_comps = [],\n",
    "              statsfile = None,\n",
    "              comp_type = \"HolmSidak\",\n",
    "              figfile = None):\n",
    "    \"\"\"\n",
    "    labelled_line_groups -> list of lists, where each sublist contains labelled groups\n",
    "    \"\"\"\n",
    "    # First, get some basic plotting information\n",
    "    plotting_info = [get_data_info(line) for line in labelled_line_groups]\n",
    "    # Then manage the statistics\n",
    "    if statsfile != None:\n",
    "        perform_line_statistics(labelled_line_groups, \n",
    "                                ignore_comps, \n",
    "                                comp_type, \n",
    "                                statsfile)\n",
    "    # Begin plotting c::\n",
    "    if ylims == None:\n",
    "        ylims = floor(min([item for item in gh.unpack_list(labelled_line_groups) if type(item) in [int, float]])), ceil(max([item for item in gh.unpack_list(labelled_line_groups) if type(item) in [int, float]]))\n",
    "    # \n",
    "    fig, ax = plt.subplots(figsize = (6,6))\n",
    "    # \n",
    "    for i in range(len(labelled_line_groups)):\n",
    "        #\n",
    "        ax.plot(plotting_info[i][0][\"centers\"],\n",
    "                plotting_info[i][0][\"means\"],\n",
    "                color = colours[i],\n",
    "                label = group_labs[i],\n",
    "                linestyle = linestyles[i])\n",
    "        #\n",
    "        for j in range(len(labelled_line_groups[i])):\n",
    "            add_errorbar(ax, \n",
    "                         plotting_info[i][0][\"centers\"][j],\n",
    "                         plotting_info[i][0][\"means\"][j],\n",
    "                         plotting_info[i][0][\"sems\"][j],\n",
    "                         color = colours[i])\n",
    "            if show_points:\n",
    "            #\n",
    "                ax.scatter(plotting_info[i][0][\"xs\"][j],\n",
    "                           plotting_info[i][1][j][1],\n",
    "                           color = colours[i],\n",
    "                           edgecolor = \"black\", alpha = 0.3,\n",
    "                           marker = markers[i],\n",
    "                           s = 10)\n",
    "            else:\n",
    "            #\n",
    "                ax.scatter(plotting_info[i][0][\"centers\"],\n",
    "                           plotting_info[i][0][\"means\"],\n",
    "                           color = colours[i],\n",
    "                           edgecolor = \"black\", alpha = 0.3,\n",
    "                           marker = markers[i],\n",
    "                           s = 30)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    xticks = find_centres(plotting_info)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xlabels[:len(xticks)],\n",
    "                       fontfamily = \"sans-serif\", \n",
    "                       font = \"Arial\", \n",
    "                       fontweight = \"bold\", \n",
    "                       fontsize = 12,\n",
    "                       rotation = 45,\n",
    "                       ha = \"center\")\n",
    "    ax.set_ylim(*ylims)\n",
    "    mph.update_ticks(ax, which = \"y\")\n",
    "    ax.set_ylabel(ylabel, fontfamily = \"sans-serif\",\n",
    "                  font = \"Arial\", fontweight = \"bold\",\n",
    "                  fontsize = 14)\n",
    "    if show_legend:\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  prop = mpl_fm.FontProperties(family = \"sans-serif\",\n",
    "                                               weight = \"bold\"))\n",
    "    if figfile == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(figfile)\n",
    "    plt.close()\n",
    "    return None\n",
    "\n",
    "def replace_neg(a_list, value = float(\"nan\")):\n",
    "    \"\"\"\n",
    "    replace any value <0 with 0\n",
    "    \"\"\"\n",
    "    newlist = []\n",
    "    for item in a_list:\n",
    "        try:\n",
    "            truth = item < 0\n",
    "        except:\n",
    "            newlist.append(item)\n",
    "        else:\n",
    "            if truth:\n",
    "                newlist.append(value)\n",
    "            else:\n",
    "                newlist.append(item)\n",
    "    return newlist\n",
    "\n",
    "def safe_log2(number):\n",
    "    try:\n",
    "        log2(number)\n",
    "    except:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        return log2(number)\n",
    "    \n",
    "#\n",
    "#\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51e8196-8a22-48b3-ac4e-2f7cd483b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "#\n",
    "exp_types = [\"proteomics\", \"titr\"]\n",
    "\n",
    "targets = [\"ERK\", \"LAT\", \"LCK\", \"PLC\"]\n",
    "proteomics_targets = [\"PLC\", \"LAT\"]\n",
    "cell_stims = [\"car\", \"t2kb\", \"ab\"]\n",
    "titr_conds = [\"0 min\", \"2.5 m\", \"5 m\", \"7.5 m\", \"10 m\", \"15 m\", \"20 m\"]\n",
    "prot_conds = [\"0 min\", \"2.5 m\", \"10 m\"]\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e66e1fd7-406d-4e50-b546-14329f598f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_negs(a_list):\n",
    "    newlist = []\n",
    "    for item in a_list:\n",
    "        if item < 0:\n",
    "            newlist.append(float(\"nan\"))\n",
    "        else:\n",
    "            newlist.append(item)\n",
    "    return newlist\n",
    "\n",
    "def replace_partner_nans(target_list, load_list):\n",
    "    assert len(target_list) == len(load_list), \"You need the same number of loading controls as target signals, silly\"\n",
    "    newtarg = []\n",
    "    newload = []\n",
    "    for i in range(len(target_list)):\n",
    "        if target_list[i] != target_list[i] or load_list[i] != load_list[i]:\n",
    "            newtarg.append(float(\"nan\"))\n",
    "            newload.append(float(\"nan\"))\n",
    "        else:\n",
    "            newtarg.append(target_list[i])\n",
    "            newload.append(load_list[i])\n",
    "    return newtarg, newload\n",
    "\n",
    "def manage_a_file(file, \n",
    "                  groups,\n",
    "                  signals_per_group = 2,\n",
    "                  target = \"685Ex-720Em\", \n",
    "                  load = \"785Ex-820Em\",\n",
    "                  norm_string = \"0 min\"):\n",
    "    # First, read the file\n",
    "    df = pd.read_excel(file)\n",
    "    #next, extract the signal values.\n",
    "    # replace any negative values with float(\"nan\") -> these are not quantifiable\n",
    "    target_signal = replace_negs(wh.get_signal(df, target))\n",
    "    load_signal = replace_negs(wh.get_signal(df, load))\n",
    "    # replace partner values with NANs\n",
    "    target_signal, load_signal = replace_partner_nans(target_signal, load_signal)\n",
    "    # do the LI-COR correction, which will give NANs if NAN is present\n",
    "    cor_sig = wh.licor_correction(target_signal, load_signal)\n",
    "    # group the signals using the groups list (should already be in order)\n",
    "    labelled_groups = [[groups[i], cor_sig[signals_per_group*i:signals_per_group*(i+1)]] for i in range(len(groups))]\n",
    "    # find the mean of the norm group\n",
    "    mean = [sh.mean(group[1]) for group in labelled_groups if group[0] == norm_string][0]\n",
    "    # normalise and log-transform\n",
    "    labelled_groups = [[group[0], [log2(val/mean) for val in group[1]]] for group in labelled_groups]\n",
    "    return labelled_groups\n",
    "\n",
    "def manage_all_files(files_list,\n",
    "                     stim_list,\n",
    "                     target_list,\n",
    "                     return_dict,\n",
    "                     timepoints = titr_conds,\n",
    "                     signals_per_group = 2,\n",
    "                     norm_string = \"0 min\"):\n",
    "    keys = list(return_dict[stim_list[0]][target_list[0]].keys())\n",
    "    # Loop over all the files\n",
    "    for f in files_list:\n",
    "        # and loop over all the stim conditions\n",
    "        for s in stim_list:\n",
    "            # then, if that stim condition is in the file\n",
    "            if s in f:\n",
    "                # then loop over the targets\n",
    "                for t in target_list:\n",
    "                    # and if that target is in the file\n",
    "                    if t in f:\n",
    "                        # loop over the keys\n",
    "                        for k in keys:\n",
    "                            # if the key is in this file, then we have everything we need\n",
    "                            if k in f:\n",
    "                                # Grab the data\n",
    "                                data = manage_a_file(f,\n",
    "                                                     timepoints,\n",
    "                                                     signals_per_group = signals_per_group,\n",
    "                                                     norm_string = norm_string)\n",
    "                                # and add it to the appropriate subsubsubsubdict\n",
    "                                if return_dict[s][t][k] == {}:\n",
    "                                    for d in data:\n",
    "                                        return_dict[s][t][k][d[0]] = d[1]\n",
    "                                else:\n",
    "                                    for d in data:\n",
    "                                        return_dict[s][t][k][d[0]] += d[1]\n",
    "    return return_dict\n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f43c66-a621-4768-a22e-e6ee20e0179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titr_ylims = {\"ERK\": [-1,7],\n",
    "         \"LCK\": [-2,4],\n",
    "         \"PLC\": [-1,7],\n",
    "         \"LAT\": [-2,6]}\n",
    "          \n",
    "\n",
    "all_titr_data = { stim : {targ : {\"dmso\" : {},\n",
    "                          \"01rdn\" : {},\n",
    "                          \"_1rdn\" : {},\n",
    "                          \"10rdn\" : {},\n",
    "                          \"01soq\" : {},\n",
    "                          \"_1soq\" : {},\n",
    "                          \"10soq\" : {}} for targ in targets}\n",
    "            for stim in cell_stims}\n",
    "\n",
    "\n",
    "titr_files = glob.glob(\"./input_excels/titr*/*.xls\")\n",
    "\n",
    "d = manage_all_files(titr_files, cell_stims, targets, all_titr_data)\n",
    "d = {key1 : {key2 : {key3 : [[key4, value4] for key4, value4 in value3.items()] for key3, value3 in value2.items()}\n",
    "                    for key2, value2 in value1.items()}\n",
    "     for key1, value1 in d.items()}\n",
    "\n",
    "# Key1 = stim type\n",
    "for key1, value1 in d.items():\n",
    "    # key2 = western target\n",
    "    for key2, value2 in value1.items():\n",
    "        # value has drug_condition : timecourse_data, and we want to plot all of these on 1 graph for a target\n",
    "        # first, logically ignore comparisons that arent't relevant\n",
    "        g_labs = [key3 for key3, value3 in value2.items()]\n",
    "        labelled_vals = [[[key3+pair[0], pair[1]] for pair in value3]for key3, value3 in value2.items()]\n",
    "        ignore = _logical_ignore_comps(labelled_vals,\n",
    "                                       group_strs = g_labs,\n",
    "                                       xgroup_strs = titr_conds)\n",
    "        # Then, we need to plot with all the fun stuff\n",
    "        line_plot(labelled_vals,\n",
    "                  ylims = titr_ylims[key2],\n",
    "                  colours = [\"hotpink\",\n",
    "                             \"lightskyblue\",\n",
    "                             \"steelblue\",\n",
    "                             \"blue\",\n",
    "                             \"lavender\",\n",
    "                             \"mediumpurple\",\n",
    "                             \"indigo\"],\n",
    "                  markers = [\"o\", \"s\", \"s\", \"s\", \"D\", \"D\", \"D\"],\n",
    "                  linestyles = [\"dashdot\" for i in range(7)],\n",
    "                  xlabels = titr_conds,\n",
    "                  show_points = False,\n",
    "                  show_legend = True,\n",
    "                  group_labs = [\"DMSO\", \n",
    "                                r\"0.1 $\\mu$M RDN\", \n",
    "                                r\"1 $\\mu$M RDN\", \n",
    "                                r\"10 $\\mu$M RDN\",\n",
    "                                r\"0.1 $\\mu$M Soq.\", \n",
    "                                r\"1 $\\mu$M Soq.\", \n",
    "                                r\"10 $\\mu$M Soq.\"],\n",
    "                  ignore_comps = ignore,\n",
    "                  statsfile = f\"./stats/{key1}_{key2}_timecourse_stats\",\n",
    "              figfile = f\"./figs/{key1}_{key2}_timecourse_graph.pdf\",\n",
    "              comp_type = \"HolmSidak\",\n",
    "              ylabel = r\"$\\log_{2}$ Fold Change\")\n",
    "        \n",
    "\n",
    "# Now I have all the data in dictionaries organised as follows:\n",
    "    # Cell type/Stimulation type (ab, t2kb, car)\n",
    "        # Western target (PLC ERK LAT LCK)\n",
    "            # Drug/concentration\n",
    "                # timepoints/data (as a key:value pair, turn into list things)\n",
    "# Once I turn the sub-most dicts into lists, this should be an easy line plot <3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54459ecc-5b64-4b57-86b8-2b0e97a65d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "/tmp/ipykernel_13409/1652314666.py:1: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprot_ylims = {\"PLC\": [-1,7],\\n              \"LAT\": [-2,6]}\\n\\n\\nall_prot_data = { stim : {targ : {\"dmso\" : {},\\n                          \"rdn\" : {},\\n                          \"soq\" : {}} for targ in proteomics_targets}\\n            for stim in cell_stims}\\n\\n\\nprot_files = glob.glob(\"./input_excels/proteomics*/*.xls\")\\n\\ndd = manage_all_files(titr_files, cell_stims, proteomics_targets, all_prot_data, signals_per_group = 5)\\ndd = {key1 : {key2 : {key3 : [[key4, value4] for key4, value4 in value3.items()] for key3, value3 in value2.items()}\\n                    for key2, value2 in value1.items()}\\n     for key1, value1 in dd.items()}\\n\\n# Key1 = stim type\\nfor key1, value1 in dd.items():\\n    # key2 = western target\\n    for key2, value2 in value1.items():\\n        print(key1, key2)\\n        # value has drug_condition : timecourse_data, and we want to plot all of these on 1 graph for a target\\n        # first, logically ignore comparisons that arent\\'t relevant\\n        g_labs = [key3 for key3, value3 in value2.items()]\\n        ignore = _logical_ignore_comps([value3 for key3, value3 in value2.items()],\\n                                       group_strs = g_labs,\\n                                       xgroup_strs = prot_conds)\\n        print([value3 for key3, value3 in value2.items()])\\n        # Then, we need to plot with all the fun stuff\\n        line_plot([value3 for key3, value3 in value2.items()],\\n                  #ylims = prot_ylims[key2],\\n                  colours = [\"hotpink\",\\n                             \"blue\",\\n                             \"indigo\"],\\n                  markers = [\"o\", \"s\", \"D\"],\\n                  linestyles = [\"dashdot\" for i in range(3)],\\n                  xlabels = titr_conds,\\n                  show_points = False,\\n                  show_legend = True,\\n                  group_labs = [\"DMSO\", \\n                                r\"10 $\\\\mu$M RDN\",\\n                                r\"10 $\\\\mu$M Soq.\"],\\n                  ignore_comps = ignore,\\n                  statsfile = f\"./stats/{key1}_{key2}_proteomics_stats\",\\n              figfile = f\"./figs/{key1}_{key2}_proteomics_graph.pdf\",\\n              comp_type = \"HolmSidak\",\\n              ylabel = r\"$\\\\log_{2}$ Fold Change\")\\n        break\\n    break\\n\\n\\n# Now I have all the data in dictionaries organised as follows:\\n    # Cell type/Stimulation type (ab, t2kb, car)\\n        # Western target (PLC ERK LAT LCK)\\n            # Drug/concentration\\n                # timepoints/data (as a key:value pair, turn into list things)\\n# Once I turn the sub-most dicts into lists, this should be an easy line plot <3\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "prot_ylims = {\"PLC\": [-1,7],\n",
    "              \"LAT\": [-2,6]}\n",
    "          \n",
    "\n",
    "all_prot_data = { stim : {targ : {\"dmso\" : {},\n",
    "                          \"rdn\" : {},\n",
    "                          \"soq\" : {}} for targ in proteomics_targets}\n",
    "            for stim in cell_stims}\n",
    "\n",
    "\n",
    "prot_files = glob.glob(\"./input_excels/proteomics*/*.xls\")\n",
    "\n",
    "dd = manage_all_files(titr_files, cell_stims, proteomics_targets, all_prot_data, signals_per_group = 5)\n",
    "dd = {key1 : {key2 : {key3 : [[key4, value4] for key4, value4 in value3.items()] for key3, value3 in value2.items()}\n",
    "                    for key2, value2 in value1.items()}\n",
    "     for key1, value1 in dd.items()}\n",
    "\n",
    "# Key1 = stim type\n",
    "for key1, value1 in dd.items():\n",
    "    # key2 = western target\n",
    "    for key2, value2 in value1.items():\n",
    "        print(key1, key2)\n",
    "        # value has drug_condition : timecourse_data, and we want to plot all of these on 1 graph for a target\n",
    "        # first, logically ignore comparisons that arent't relevant\n",
    "        g_labs = [key3 for key3, value3 in value2.items()]\n",
    "        ignore = _logical_ignore_comps([value3 for key3, value3 in value2.items()],\n",
    "                                       group_strs = g_labs,\n",
    "                                       xgroup_strs = prot_conds)\n",
    "        print([value3 for key3, value3 in value2.items()])\n",
    "        # Then, we need to plot with all the fun stuff\n",
    "        line_plot([value3 for key3, value3 in value2.items()],\n",
    "                  #ylims = prot_ylims[key2],\n",
    "                  colours = [\"hotpink\",\n",
    "                             \"blue\",\n",
    "                             \"indigo\"],\n",
    "                  markers = [\"o\", \"s\", \"D\"],\n",
    "                  linestyles = [\"dashdot\" for i in range(3)],\n",
    "                  xlabels = titr_conds,\n",
    "                  show_points = False,\n",
    "                  show_legend = True,\n",
    "                  group_labs = [\"DMSO\", \n",
    "                                r\"10 $\\mu$M RDN\",\n",
    "                                r\"10 $\\mu$M Soq.\"],\n",
    "                  ignore_comps = ignore,\n",
    "                  statsfile = f\"./stats/{key1}_{key2}_proteomics_stats\",\n",
    "              figfile = f\"./figs/{key1}_{key2}_proteomics_graph.pdf\",\n",
    "              comp_type = \"HolmSidak\",\n",
    "              ylabel = r\"$\\log_{2}$ Fold Change\")\n",
    "        break\n",
    "    break\n",
    "        \n",
    "\n",
    "# Now I have all the data in dictionaries organised as follows:\n",
    "    # Cell type/Stimulation type (ab, t2kb, car)\n",
    "        # Western target (PLC ERK LAT LCK)\n",
    "            # Drug/concentration\n",
    "                # timepoints/data (as a key:value pair, turn into list things)\n",
    "# Once I turn the sub-most dicts into lists, this should be an easy line plot <3\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88876f98-6c03-4737-8439-74989456ad98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c418e8c-2d02-4230-a1e9-bc1f888e3719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0e6f2-8bd4-4aea-ba76-bfaae4864755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
